optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.0005,
  weight_decay : 0.05
}}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 300,
    initial_epochs : 10
}}

dataset : {
  train : { _base_: cfgs/dataset/ModelNet40.yaml,
            others: {subset: 'train'}},
  val : { _base_: cfgs/dataset/ModelNet40.yaml,
            others: {subset: 'test'}},
  test : { _base_: cfgs/dataset/ModelNet40.yaml,
            others: {subset: 'test'}}}

model : {
  NAME: Point_M2AE_ModelNet40,
  group_sizes: [16, 8, 8],
  num_groups: [512, 256, 64],
  smooth: 0.3,
  # hierarchical encoder
  encoder_depths: [5, 5, 5],
  encoder_dims: [96, 192, 384],
  local_radius: [0.32, 0.64, 1.28],  
  # others
  drop_path_rate: 0.1,
  num_heads: 6,
}

npoints: 1024
total_bs : 32
step_per_update : 1
max_epoch : 300
grad_norm_clip : 10
